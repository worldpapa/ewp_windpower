# -*- coding: utf-8 -*-
"""wind_power.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s7xfthSkxm1yWMKIVBRRlloLwmwuDPkq
"""

import pandas as pd
import numpy as np
import math
import random
from numpy import array
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

import tensorflow as tf
import keras
from tensorflow.keras import Sequential, layers
from tensorflow.keras.layers import Dense, LSTM, Dropout
from keras.callbacks import ModelCheckpoint, EarlyStopping

df1 = pd.read_csv('data/codebook.csv')
df2 = pd.read_csv('data/submit_sample.csv') # 21-09-15 ~ 21-10-30
df3 = pd.read_csv('data/test_input.csv') # 21-09-01 ~ 21-10-29
X_train = pd.read_csv('data/train_input.csv') # 20-01-01 ~ 21-08-30
y_train = pd.read_csv('data/train_output.csv') # 20-01-15 ~ 21-08-31

w20 = pd.read_csv('data/w20.csv', encoding = 'EUC-KR')
w20 = pd.read_csv('data/w21.csv', encoding = 'EUC-KR') # ~21-10-30

"""## X_train, y_train을 병합하여 데이터프레임 생성"""

df = pd.merge(X_train, y_train, how='outer', left_on='time', right_on='time')
df = df.dropna(axis=0)
df.head(3)

"""## 기상데이터 전처리"""

w20 = w20.fillna(0)
w21 = w21.fillna(0)
weather = w20.append(w21)
weather['time'] = weather['일시'].apply(lambda x: x[:-3])
weather.head(3)

weather = weather.drop(['지점', '지점명', '일시'], axis=1)

"""## 기상정보 데이터와 데이터프레임 병합"""

df = pd.merge(df, weather, how='left', left_on='time', right_on='time')
df.head(3)

"""## 상관분석"""

ft = df.iloc[:,1:]

sc = MinMaxScaler()

ft[ft.columns] = sc.fit_trasform(ft[ft.columns])
cor = ft.corr(method='pearson')

cor = cor.unstack()
cor = pd.DataFrame(cor['active_energy_production'].sort_values(ascending=False), columns = ['active_energy_production'])
cor.style.background_gradient(cmap='viridis')

"""## 변수 선별"""

important = cor[(cor['active_energy_production'] > 0.5) | (cor['active_energy_production'] < -0.5)].index

n, bins, patches = plt.hist(df['active_energy_production'], bins = 50)

"""## 타겟 설정"""

df['target'] = df['active_energy_production'].shift(-24)
df.tail(3)

"""## 데이터프레임 전처리"""

df = df[df['target'].notnull()]
X = df[important]
X = df.drop(['time', 'active_energy_production', 'target'], axis=1).reset_index(drop=True)
y = df['target'].reset_index(drop=True)
X.head(3)

feature = X.columns
scaler = MinMaxScaler()
X = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

"""## 데이터 변환"""

X_train = X_train.reshape(-1,1,len(feature))
X_test = X_test.reshape(-1,1,len(feature))
y_train = y_train.values.reshape(-1,1,1)
y_test = y_test.values.reshape(-1,1,1)

"""## 모델링"""

model = Sequential()
model.add(layer.Activation('relu'))
model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, input_shape=(24,len(feature)), return_sequences=True))
model.add(Dropout(0.1))
model.add(layers.Dense(30))
model.add(Dropout(0.1))
model.add(layers.Dense(1))
model.compile(optimizer='adam', loss='mae')
early_stopping = EarlyStopping(patience=30)
model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=1)

"""## 모델 예측 결과 시각화"""

y_pred = model.predict(X_test)

plt.plot(np.array(y_test.reshape(-1,1)), label='Real')
plt.plot(np.array(y_pred.reshape(-1,1)), label='Predict')
plt.legend()
plt.show()

"""## 모델 성능 평가"""

MAE = mean_absolute_error(y_test.reshape(-1,1), y_pred.reshape(-1,1))
print(MAE)

"""## 예측 결과 제출용 모델 생성 코드"""

df1 = pd.read_csv('data/codebook.csv')
df2 = pd.read_csv('data/submit_sample.csv') # 21-09-15 ~ 21-10-30
df3 = pd.read_csv('data/test_input.csv') # 21-09-01 ~ 21-10-29
X_train = pd.read_csv('data/train_input.csv') # 20-01-01 ~ 21-08-30
y_train = pd.read_csv('data/train_output.csv') # 20-01-15 ~ 21-08-31

w20 = pd.read_csv('data/w20.csv', encoding = 'EUC-KR')
w20 = pd.read_csv('data/w21.csv', encoding = 'EUC-KR') # ~21-10-30

w20 = w20.fillna(0)
w21 = w21.fillna(0)
weather = w20.append(w21)
weather['time'] = weather['일시'].apply(lambda x: x[:-3])
weather.head(3)

weather = weather.drop(['지점', '지점명', '일시'], axis=1)

df = pd.merge(df, weather, how='left', left_on='time', right_on='time')

df['target'] = df['active_energy_production'].shift(-24)
df = df[df['target'].notnull()]

"""## 학습데이터"""

X = df[important].drop(['active_energy_production']. axis=1).reset_index(drop=True)
y = df['target'].reset_index(drop=True)

feature = X.columns
scaler = MinMaxScaler()
X = scaler.fit_transform(X)
X_train = X.reshape(-1,1,len(feature))
y_train = y.values.reshape(-1,1,1)

"""## 학습"""

model = Sequential()
model.add(layer.Activation('relu'))
model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, input_shape=(24,len(feature)), return_sequences=True))
model.add(Dropout(0.1))
model.add(layers.Dense(30))
model.add(Dropout(0.1))
model.add(layers.Dense(1))
model.compile(optimizer='adam', loss='mae')
model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=1)

"""## 예측에 사용할 X_test 데이터 전처리"""

X_test = pd.merge(df3, weather, how='left', left_on='time', right_on='time')
X_test = X_test.drop('time', axis=1).reset_index(drop=True)
X_test = X_test[feature]
feature = X_test.columns

"""## 스케일링"""

X_test[feature] = scaler.transform(X_test[feature])
X_test = X_test.values.reshape(-1,1,len(feature))

y_pred = model.predict(X_test)
y_pred = y_pred.reshape(1,-1)[0]

"""## 제출"""

df2['active_energy_production'] = y_pred[312:]

df2.to_csv('submit.csv', index=False)